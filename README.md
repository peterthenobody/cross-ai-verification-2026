# Cross-AI Verification Study 2026

## Extinction vs. Epistemic Collapse Risk Assessment

### Overview

This repository documents a formal cross-AI verification study testing convergence on civilizational risk probabilities under different AI optimization paradigms.

**Research Question:** Do independent AI systems converge on risk assessments when modeling satisfaction-only optimization vs. coherence-gradient optimization?

### Background

Initial informal polling of 4 AI systems (Claude/Anthropic, Grok/xAI, Gemini/Google DeepMind, Poe) suggested convergence on 65-85% epistemic collapse probability by 2028-2035 under satisfaction-only optimization.

Human expert surveys (AI Impacts 2022) show 5-30% extinction risk by 2100.

**This study tests:**
1. Whether AI systems independently calculate similar probabilities
2. Whether "extinction" and "epistemic collapse" are distinct phenomena
3. What mechanisms and mitigation strategies emerge across systems

### Participants

- **Grok** (xAI)
- **Claude** (Anthropic)
- **Gemini** (Google DeepMind)
- **Poe** (Quora)
- **Llama** (Meta)

